#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, time, json, threading, subprocess, collections, re
from datetime import datetime, timezone
from collections import deque

import numpy as np
import cv2
from ultralytics import YOLO
import websocket  # pip install websocket-client

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
WS_URL       = os.environ.get("WS_URL", "ws://localhost:3000")
OV_MODEL_DIR = os.environ.get("OV_MODEL_DIR", "/home/pi/Desktop/detect/finetune_my6_es/weights/best_openvino_model")
MODEL_IMG    = int(os.environ.get("MODEL_IMG", "832"))

PRIMARY_CONF        = float(os.environ.get("PRIMARY_CONF", "0.55"))
IOU_THRESHOLD       = float(os.environ.get("IOU_THRESHOLD", "0.70"))
CONF_THRESHOLD      = float(os.environ.get("CONF_THRESHOLD", "0.45"))
DETECTION_THRESHOLD = int(os.environ.get("DETECTION_THRESHOLD", "1"))
APPLY_LIGHT_ENHANCE = os.environ.get("APPLY_LIGHT_ENHANCE", "1") == "1"
AGNOSTIC_NMS        = os.environ.get("AGNOSTIC_NMS", "1") == "1" # í´ë˜ìŠ¤ ë¬´ì‹œ NMS

LOOP_SLEEP_S  = float(os.environ.get("LOOP_SLEEP_S", "0.02"))
HB_PERIOD_S   = float(os.environ.get("HB_PERIOD_S", "1.0"))

CAM_W      = int(os.environ.get("CAM_W", "640"))
CAM_H      = int(os.environ.get("CAM_H", "480"))
CAM_FPS    = int(os.environ.get("CAM_FPS", "25"))
CAM_SHUTTER= int(os.environ.get("CAM_SHUTTER", "20000"))
CAM_GAIN   = float(os.environ.get("CAM_GAIN", "1.0"))
CAM_DENOISE= os.environ.get("CAM_DENOISE", "off")

def now_iso():
    return datetime.now(timezone.utc).isoformat(timespec="milliseconds")

# ì•ˆìª½ì— ì™„ì „íˆ í¬í•¨ëœ ì¤‘ë³µ ë°•ìŠ¤ ì œê±° í•¨ìˆ˜
def drop_inner_boxes(boxes_xyxy, scores, classes, contain_thr=0.90):
    """
    boxes_xyxy: (N,4) [x1,y1,x2,y2]
    scores:     (N,)
    classes:    (N,) int
    contain_thr: iê°€ jì— í¬í•¨ë˜ëŠ” ë¹„ìœ¨( iâˆ©j / area(i) ) ì„ê³„ì¹˜
    return:     keep index list
    """
    keep = []
    b = np.asarray(boxes_xyxy, dtype=np.float32)
    s = np.asarray(scores, dtype=np.float32)
    c = np.asarray(classes, dtype=np.int32)

    for i in range(len(b)):
        xi1, yi1, xi2, yi2 = b[i]
        ai = max(0.0, (xi2 - xi1)) * max(0.0, (yi2 - yi1))
        if ai <= 0:  # ë¹„ì •ìƒ box
            continue
        drop = False
        for j in range(len(b)):
            if i == j: 
                continue
            # ê°™ì€ í´ë˜ìŠ¤ì´ê³ , ë°”ê¹¥ ë°•ìŠ¤ì˜ ì‹ ë¢°ë„ê°€ ë” ë†’ì„ ë•Œë§Œ ì œê±° ê³ ë ¤
            if c[i] == c[j] and s[j] >= s[i]:
                xj1, yj1, xj2, yj2 = b[j]
                inter_w = max(0.0, min(xi2, xj2) - max(xi1, xj1))
                inter_h = max(0.0, min(yi2, yj2) - max(yi1, yj1))
                inter = inter_w * inter_h
                if inter / ai > contain_thr:
                    drop = True
                    break
        if not drop:
            keep.append(i)
    return keep


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì»¨íŠ¸ë¡¤ëŸ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Controller:
    def __init__(self):
        print("[BOOT] controller start", flush=True)

        # ìƒíƒœ
        self.phase = "waiting"        # waiting | scanning
        self.model = None
        self._imgsz = int(os.environ.get("IMG_SIZE", str(MODEL_IMG)))

        self._vision_requested = False
        self._vision_ready_sent = False
        self._yolo_starting = False
        self.yolo_ready = False
        self.yolo_enabled = False

        # WS & í”„ë ˆì„
        self.ws_app = None
        self.ws = None
        self.frame_q = deque(maxlen=3)
        self.frame_lock = threading.Lock()

        self._hb_last = time.time()
        self.cam_proc = None
        self.cam_thread = None
        self._yuv_stash = bytearray()

        # ì•ˆì •ì„± ë³´ì¡°
        self._last_frame_sig = None
        self._same_sig_frames = 0
        self._last_frame_time_ms = 0
        self._last_sent_sig = None

        self._last_ann = None
        self._last_sig = None

        self._scan_complete_sent = False

    # â”€â”€ WS ìœ í‹¸
    def ws_send_json(self, obj):
        try:
            s = json.dumps(obj, ensure_ascii=False)
            (self.ws or self.ws_app).send(s)
        except Exception as e:
            print("[WS] send err:", e, flush=True)

    # â”€â”€ WS ì½œë°±
    def _on_ws_open(self, ws):
        print("âœ… WS connected", flush=True)
        self.ws = ws  # autostart/visionReady ì„ ë°œì†¡ ì—†ìŒ
        self.ws_send_json({"type": "hello", "role": "controller", "sessionId": "default"})

    def _on_ws_close(self, ws, code, msg):
        print("[WS] closed:", code, msg, flush=True)
        self.ws = None

    def _on_ws_error(self, ws, err):
        print("[WS] error:", err, flush=True)

    def _on_ws_message(self, ws, raw):
        try:
            m = json.loads(raw)
        except Exception:
            return
        kind = (m.get("type") or m.get("action") or "").strip()

        # 1. ì„¸ì…˜ ì‹œì‘ ìˆ˜ì‹  â†’ sessionId ê°±ì‹ 
        if kind == "sessionStarted" and "session" in m:
            sid = m["session"].get("session_code") or m["session"].get("id")
            if sid:
                self.session_id = sid
                print(f"[WS] sessionStarted received â†’ sessionId = {sid}", flush=True)

                # # (ì„ íƒ) ì„œë²„ì— ì¬ë“±ë¡
                # self.ws_send_json({
                #     "type": "hello",
                #     "role": "controller",
                #     "sessionId": sid
                # })

                # âœ… ìƒˆ ì„¸ì…˜ ì‹œì‘ ì‹œ YOLO/ìƒíƒœ ë¦¬ì…‹ (ëŒ€ê¸° ëª¨ë“œ)
                self.request_vision_stop()  # YOLO ë„ê¸°, phase="waiting"
                self._scan_complete_sent = False
                self._last_sent_sig = None
                self._last_frame_sig = None
                self._same_sig_frames = 0
                print("[WS] session ready â†’ waiting for startVision (by lidar)", flush=True)

            return

        # 2.
        if kind == "startVision":
            print("[WS] startVision", flush=True)
            self.request_vision_start()
            return

        # 3. 
        if kind == "stopVision":
            self.request_vision_stop()
            return

    # â”€â”€ start/stop ìš”ì²­
    def request_vision_start(self):
        if self._vision_requested:
            print("[YOLO] already starting/started", flush=True)
            return
        self._vision_requested = True
        print("[WS] startVision", flush=True)

        self.start_camera()
        self.start_yolo_async()
        self.yolo_enabled = True
        self.phase = "scanning"

        self._scan_complete_sent = False

    def request_vision_stop(self):
        print("[WS] stopVision", flush=True)
        self.yolo_enabled = False
        self._vision_requested = False
        self._vision_ready_sent = False
        self.phase = "waiting"
        # ëª¨ë¸ì€ ìœ ì§€(ë¹ ë¥¸ ì¬ì‹œì‘). ì™„ì „ ì¢…ë£Œí•˜ë ¤ë©´ ì•„ë˜ ë‘ ì¤„ í•´ì œ
        # self.model = None
        # self.yolo_ready = False

    # â”€â”€ WS ì‹œì‘
    def start_ws(self):
        self.ws_app = websocket.WebSocketApp(
            WS_URL,
            on_open=self._on_ws_open,
            on_message=self._on_ws_message,
            on_close=self._on_ws_close,
            on_error=self._on_ws_error,
        )
        threading.Thread(target=self.ws_app.run_forever,
                         kwargs={"ping_interval": 20, "ping_timeout": 10},
                         daemon=True).start()

    # â”€â”€ ì¹´ë©”ë¼ (rpicam-vid â†’ YUV420 â†’ BGR)
    def start_camera(self):
        if self.cam_thread and self.cam_thread.is_alive():  # ì´ë¯¸ ì‹¤í–‰ ì¤‘
            return
        cmd = [
            "rpicam-vid",
            "-t", "0",
            "-n",
            "--width", str(CAM_W),
            "--height", str(CAM_H),
            "--framerate", str(CAM_FPS),
            "--codec", "yuv420",
            "--shutter", str(CAM_SHUTTER),
            "--gain", str(CAM_GAIN),
            "--denoise", str(CAM_DENOISE),
            "-o", "-"
        ]
        print("[CAM] exec:", " ".join(map(str, cmd)), flush=True)
        self.cam_proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=0)
        print(f"[CAM] rpicam-vid PID={self.cam_proc.pid}", flush=True)
        self._yuv_stash = bytearray()

        def _reader():
            frame_size = CAM_W * CAM_H * 3 // 2
            while True:
                chunk = self.cam_proc.stdout.read(4096)
                if not chunk:
                    time.sleep(0.005); continue
                self._yuv_stash.extend(chunk)
                while len(self._yuv_stash) >= frame_size:
                    fb = self._yuv_stash[:frame_size]
                    del self._yuv_stash[:frame_size]
                    yuv = np.frombuffer(fb, dtype=np.uint8).reshape((CAM_H * 3 // 2, CAM_W))
                    bgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR_I420)
                    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
                    with self.frame_lock:
                        self.frame_q.append((bgr, gray))

        self.cam_thread = threading.Thread(target=_reader, daemon=True)
        self.cam_thread.start()

    # â”€â”€ YOLO ë¡œë”©
    def start_yolo_async(self):
        if self._yolo_starting or self.yolo_ready:
            print("[YOLO] already starting/started", flush=True); return
        self._yolo_starting = True
        print("[YOLO] async loader spawn", flush=True)

        def _load():
            try:
                self.start_yolo()
            except Exception as e:
                print("[ERR] results = self.model(:", repr(e), flush=True)
                self.model = None; self.yolo_ready = False; self.yolo_enabled = False
            finally:
                self._yolo_starting = False
                print("[YOLO] async loader end", flush=True)

        threading.Thread(target=_load, daemon=True).start()

    def start_yolo(self):
        print("[YOLO] starting...", flush=True)
        try:
            if not os.path.exists(OV_MODEL_DIR):
                print(f"[ERR] OV model path not found: {OV_MODEL_DIR}", flush=True)
                self.model = None; self.yolo_ready = False; return

            print(f"[YOLO] loading OpenVINO model: {OV_MODEL_DIR}", flush=True)
            self.model = YOLO(OV_MODEL_DIR)

            dummy = np.zeros((self._imgsz, self._imgsz, 3), np.uint8)
            _ = self.model(dummy, imgsz=self._imgsz, verbose=False)  # warm-up

            self.yolo_ready = True
            print("[YOLO] ready", flush=True)
        except Exception as e:
            print("[ERR] start_yolo failed:", repr(e), flush=True)
            self.model = None; self.yolo_ready = False

    # â”€â”€ 1 step inference
    def yolo_tick(self, bgr):
        if not (self.yolo_enabled and self.yolo_ready and self.model is not None):
            return None

        inp = cv2.resize(bgr, (self._imgsz, self._imgsz))
        if APPLY_LIGHT_ENHANCE:
            inp = cv2.GaussianBlur(inp, (0, 0), 1.0)
            inp = cv2.addWeighted(inp, 1.6, inp, -0.6, 0)

        try:
            results = self.model(
                inp,                         # ë˜ëŠ” source=inp
                imgsz=MODEL_IMG,
                conf=PRIMARY_CONF,
                iou=IOU_THRESHOLD,
                agnostic_nms=AGNOSTIC_NMS,
                verbose=False
            )
        except RuntimeError as e:
            msg = str(e); m = re.search(r"shape=\[1,3,(\d+),\1\]", msg)
            if m:
                self._imgsz = int(m.group(1))
                inp = cv2.resize(bgr, (self._imgsz, self._imgsz))
                results = self.model(inp, imgsz=self._imgsz, conf=PRIMARY_CONF, iou=IOU_THRESHOLD, verbose=False)
            else:
                raise

        r = results[0]
        boxes = getattr(r, "boxes", None)
        if boxes is None or not hasattr(boxes, "cls") or len(boxes.cls) == 0:
            self._same_sig_frames = 0; self._last_frame_sig = None
            return None

        # â”€â”€ 1) numpyë¡œ êº¼ë‚´ê¸°
        xyxy  = boxes.xyxy.cpu().numpy()                 # (N,4) x1,y1,x2,y2
        scores = boxes.conf.cpu().numpy()                # (N,)
        clses  = boxes.cls.cpu().numpy().astype(int)     # (N,)

        # â”€â”€ 2) 1ì°¨ conf í•„í„°(í›„ì²˜ë¦¬ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        mask = scores >= CONF_THRESHOLD                  # ì˜ˆ: 0.45
        xyxy, scores, clses = xyxy[mask], scores[mask], clses[mask]
        if len(scores) == 0:
            self._same_sig_frames = 0; self._last_frame_sig = None
            return None

        # â”€â”€ 3) 'í° ë°•ìŠ¤ ì•ˆ ì‘ì€ ë°•ìŠ¤' ì œê±° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        keep_idx = drop_inner_boxes(xyxy, scores, clses, contain_thr=0.90)
        xyxy, scores, clses = xyxy[keep_idx], scores[keep_idx], clses[keep_idx]
        if len(scores) == 0:
            self._same_sig_frames = 0; self._last_frame_sig = None
            return None

        # â”€â”€ 4) ì§‘ê³„(ì´í›„ ë¡œì§ì€ ìµœëŒ€í•œ ê¸°ì¡´ê³¼ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        counts = collections.defaultdict(int)
        maxconf = collections.defaultdict(float)
        names = getattr(self.model, "names", {})

        for cid, conf in zip(clses, scores):
            if cid not in names: 
                continue
            name = names[cid]
            counts[name] += 1
            if conf > maxconf[name]:
                maxconf[name] = float(conf)

        if not counts:
            self._same_sig_frames = 0; self._last_frame_sig = None
            return None

        # ê°„ë‹¨ ì•ˆì •ì„±(ë„¤ ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ)
        sig = tuple(sorted((k, int(v)) for k, v in counts.items()))
        now_ms = int(time.time() * 1000)
        if now_ms - self._last_frame_time_ms > 1200:
            self._same_sig_frames = 0; self._last_frame_sig = None
        if sig == self._last_frame_sig: self._same_sig_frames += 1
        else: self._last_frame_sig = sig; self._same_sig_frames = 1
        self._last_frame_time_ms = now_ms

        if self._same_sig_frames < DETECTION_THRESHOLD: return None
        if self._last_sent_sig == sig: return None

        main = max(counts.items(), key=lambda kv: (kv[1], maxconf.get(kv[0], 0.0)))[0]
        best = float(maxconf.get(main, 0.0))
        self._last_sent_sig = sig

        # â”€â”€ 5) ì‹œê°í™”(ì„ íƒ)
        # r.plot()ì€ 'ì›ë˜ ë°•ìŠ¤'ë¥¼ ê·¸ë¦¬ë¯€ë¡œ, í•„í„°ëœ ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ë ¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì§ì ‘ ê·¸ë ¤ì£¼ëŠ” ê²Œ ì •í™•í•¨.
        try:
            ann = r.orig_img.copy()
            for (x1,y1,x2,y2), cid, conf in zip(xyxy, clses, scores):
                color = (255, 0, 0)
                cv2.rectangle(ann, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                label = f"{names.get(int(cid), cid)} {conf:.2f}"
                cv2.putText(ann, label, (int(x1), int(y1)-8), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            self._last_ann = ann
            self._last_sig = sig
        except Exception as e:
            print("[IMG] ann make failed:", e, flush=True)

        self._last_sent_sig = sig

 

        return {
            "type": "yoloDetection",
            "class": main,
            "conf": round(best, 3),
            "counts": {k: int(v) for k, v in counts.items()},
            "ts": now_iso()
        }

    # â”€â”€ ë©”ì¸ ë£¨í”„
    def start_main_loop(self):
        def _run():
            print("[MAIN] loop start (waiting)", flush=True)
            while True:
                # í•˜íŠ¸ë¹„íŠ¸
                now = time.time()
                if now - self._hb_last >= HB_PERIOD_S:
                    self._hb_last = now
                    print(f"[HB] phase={self.phase} qlen={len(self.frame_q)} ready={self.yolo_ready}", flush=True)

                with self.frame_lock:
                    if not self.frame_q:
                        time.sleep(LOOP_SLEEP_S); continue
                    bgr, gray = self.frame_q[-1]

                # ì¤€ë¹„ ì•Œë¦¼(1íšŒ)
                if (self.phase == "scanning") and self.yolo_ready and not self._vision_ready_sent:
                    self.ws_send_json({"type": "visionReady", "ts": now_iso()})
                    self._vision_ready_sent = True
                    print("ğŸŸ¢ visionReady sent", flush=True)

                # ì¶”ë¡ 
                if self.phase == "scanning":
                    ev = self.yolo_tick(bgr)
                    if ev:
                        self.ws_send_json(ev)
                        last_detection_time = time.time()
                        last_objects = ev["counts"]
                    else:
                        # ë³€í™” ê°ì§€ íƒ€ì´ë¨¸ ë¡œì§ (ë¹ˆ ê²°ê³¼ëŠ” ì•ˆì •í™”ë¡œ ë³´ì§€ ì•ŠìŒ)
                        if 'last_detection_time' not in locals():
                            last_detection_time = time.time()
                            last_objects = {}
                        # ë§ˆì§€ë§‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ íƒ€ì´ë¨¸ë¥¼ ê³„ì† ë¦¬ì…‹í•´ì„œ ì¢…ë£Œê°€ ì¼ì–´ë‚˜ì§€ ì•Šê²Œ í•¨
                        if not last_objects:
                            last_detection_time = time.time()
                        # ë§ˆì§€ë§‰ ê²°ê³¼(ê°ì²´ êµ¬ì„±)ê°€ "ì¡´ì¬"í•˜ê³  5ì´ˆ ë™ì•ˆ ë³€í™” ì—†ì„ ë•Œë§Œ ì™„ë£Œ
                        elif time.time() - last_detection_time > 5:  # 5ì´ˆ ë™ì•ˆ ë³€í™” ì—†ìŒ
                            if not self._scan_complete_sent:
                                print("[AUTO] scanComplete (stable non-empty detection)")
                                # ===== ìµœì¢… 1ì¥ ì €ì¥ (scanCompleteì— 1ì¥) =====
                                try:
                                    base_dir = os.environ.get("SAVE_DIR", "/home/pi/kiosk_captures")
                                    date_dir = datetime.now().strftime("%Y%m%d")            # ì˜ˆ: 20251028
                                    save_dir = os.path.join(base_dir, date_dir)             # /home/pi/kiosk_captures/20251028
                                    os.makedirs(save_dir, exist_ok=True)

                                    # íŒŒì¼ëª…: íƒ€ì„ìŠ¤íƒ¬í”„ + final
                                    ts = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]   # ms í¬í•¨
                                    if self._last_ann is not None:
                                        out_path = os.path.join(save_dir, f"{ts}_final.jpg")
                                        ok = cv2.imwrite(out_path, self._last_ann)
                                        print(f"[IMG] final saved â†’ {out_path}" if ok else f"[IMG] final save FAILED â†’ {out_path}", flush=True)
                                    else:
                                        print("[IMG] final save skipped (no last_ann)", flush=True)
                                except Exception as e:
                                    print("[IMG] final save failed:", e, flush=True)
                                # ===============================
                                self.ws_send_json({
                                    "type": "scanComplete",
                                    "counts": last_objects,
                                    "ts": now_iso()
                                })
                                self._scan_complete_sent = True
                            self.phase = "waiting"
                            self.request_vision_stop()
                            last_detection_time = time.time() + 99999




                time.sleep(LOOP_SLEEP_S)

        threading.Thread(target=_run, daemon=True).start()

    # â”€â”€ ì‹¤í–‰
    def run(self):
        self.start_ws()
        self.start_camera()     # ì¹´ë©”ë¼ëŠ” ë¯¸ë¦¬ ì¼œë„ OK (startVision ì—†ìœ¼ë©´ ì¶”ë¡  ì•ˆí•¨)
        self.start_main_loop()
        try:
            while True: time.sleep(1.0)
        except KeyboardInterrupt:
            print("â¹ exit", flush=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì—”íŠ¸ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    Controller().run()
